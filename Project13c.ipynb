{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tgrHBVM79Wi",
        "outputId": "de112943-d89d-48e7-c0ee-c812d3a6ffb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "              height            diameter             weight               hue\n",
            "0   0.10085325871588    0.10347665370087   0.66000055127054   3.1061777201591\n",
            "1  0.097520805629366     0.1201052695695               0.75   1.4520706957674\n",
            "2  0.070973086761957   0.088622489628388   0.10604947426549   3.5044594187921\n",
            "3   0.11843514045485                0.15   0.33839714871863   5.6111022342157\n",
            "                 height            diameter             weight  \\\n",
            "0      0.12493777936236    0.13190375787948   0.38616824929558   \n",
            "1      0.14492137354649    0.12500746617994               0.75   \n",
            "2     0.071892497830642                0.03    0.1631761874001   \n",
            "3     0.084260612354435   0.037681879898677   0.23151165834924   \n",
            "4                  0.07   0.090347950123449   0.19177699658224   \n",
            "..                  ...                 ...                ...   \n",
            "115    0.15324808700145     0.1301638325634   0.40118457408591   \n",
            "116    0.12021522833926    0.11607358210855   0.33882777489585   \n",
            "117    0.07556917126148   0.072067954099429   0.16160560001853   \n",
            "118    0.13137129130651   0.091788907990009    0.2781412506351   \n",
            "119    0.12825404991764    0.14820139358115   0.45533536592389   \n",
            "\n",
            "                   hue      class  \n",
            "0      2.9517669794008   Plastic   \n",
            "1      3.4378755151121   Ceramic   \n",
            "2      4.0521528606463   Plastic   \n",
            "3      6.2831853071796   Ceramic   \n",
            "4      2.1255038511543   Plastic   \n",
            "..                 ...        ...  \n",
            "115    2.1792391626888   Plastic   \n",
            "116   0.87686630388415   Plastic   \n",
            "117    3.3382783895954   Plastic   \n",
            "118    2.3833925805427   Plastic   \n",
            "119    2.6866075609372   Plastic   \n",
            "\n",
            "[120 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# I have used my google drive to load the training and testing data\n",
        "# Upload the dataset file in your google drive and change the path to run the below line\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mpl_toolkits import mplot3d\n",
        "sns.set()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# I have used my google drive to load the training and testing data\n",
        "# Upload the dataset file in your google drive and change the path to run the below line\n",
        "data= pd.read_csv('/content/drive/MyDrive/ML/Priyadataset2c.csv',dtype='object')\n",
        "test=pd.read_csv('/content/drive/MyDrive/ML/PriyaTestdata.csv',dtype='object')\n",
        "print(test)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = data.iloc[:,0:3]\n",
        "print(x_train)\n",
        "y_train = data.iloc[:,4]\n",
        "print(y_train)\n",
        "x_data = x_train\n",
        "y_data = y_train\n",
        "x_train=x_train.astype('float64')\n",
        "x_train = x_train.values\n",
        "x_train=x_train.astype('float64')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N9KDLgK7_1x",
        "outputId": "9687b84b-7710-413a-f1fd-d58b4f2daf62"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 height            diameter             weight\n",
            "0      0.12493777936236    0.13190375787948   0.38616824929558\n",
            "1      0.14492137354649    0.12500746617994               0.75\n",
            "2     0.071892497830642                0.03    0.1631761874001\n",
            "3     0.084260612354435   0.037681879898677   0.23151165834924\n",
            "4                  0.07   0.090347950123449   0.19177699658224\n",
            "..                  ...                 ...                ...\n",
            "115    0.15324808700145     0.1301638325634   0.40118457408591\n",
            "116    0.12021522833926    0.11607358210855   0.33882777489585\n",
            "117    0.07556917126148   0.072067954099429   0.16160560001853\n",
            "118    0.13137129130651   0.091788907990009    0.2781412506351\n",
            "119    0.12825404991764    0.14820139358115   0.45533536592389\n",
            "\n",
            "[120 rows x 3 columns]\n",
            "0       Plastic \n",
            "1       Ceramic \n",
            "2       Plastic \n",
            "3       Ceramic \n",
            "4       Plastic \n",
            "         ...    \n",
            "115     Plastic \n",
            "116     Plastic \n",
            "117     Plastic \n",
            "118     Plastic \n",
            "119     Plastic \n",
            "Name: class, Length: 120, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3c) Implementing the leave one out validation using only first 3 features and to compare the results with the KNN algorithm"
      ],
      "metadata": {
        "id": "XsP3FQ7jTug_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# doing one hot coding\n",
        "# representing the y values in the form of a matrix and c represent the number classes\n",
        "# the matrix is of size  len(y) and no. of classes\n",
        "def one_hot(y, c):\n",
        "    y_hot=(np.arange(np.max(y) + 1) == y[:, None]).astype(float)\n",
        "    return y_hot"
      ],
      "metadata": {
        "id": "G5A_5bVn8Mv-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just giving numbers to the class so that it is easy to predict\n",
        "for i in range(len(y_train)):\n",
        "    if y_train[i] == ' Plastic ':\n",
        "        y_train[i] = 0\n",
        "    elif y_train[i] == ' Metal ':\n",
        "        y_train[i] = 1\n",
        "    elif y_train[i] == ' Ceramic ':\n",
        "        y_train[i] = 2"
      ],
      "metadata": {
        "id": "lS5pkWcU8QvQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G_WYa6E8Sbj",
        "outputId": "a65350a4-8253-4052-f37f-5f07d69201db"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      0\n",
            "1      2\n",
            "2      0\n",
            "3      2\n",
            "4      0\n",
            "      ..\n",
            "115    0\n",
            "116    0\n",
            "117    0\n",
            "118    0\n",
            "119    0\n",
            "Name: class, Length: 120, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing the softmax regression probability function\n",
        "def softmax(a):\n",
        "    Pro_exp = np.exp(a - np.max(a))\n",
        "    for i in range(len(a)):\n",
        "        Pro_exp[i] /= np.sum(Pro_exp[i])\n",
        "    return Pro_exp"
      ],
      "metadata": {
        "id": "GKpomS_E8V-S"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using xtraining data to train the algorithm\n",
        "# fitting the function by using random values for weight and passing 1 as bias and updating the graident\n",
        "def fit(X, y, lr, c, epochs):\n",
        "    m, n = X.shape\n",
        "    # Initializing weights randomly.\n",
        "    w = np.random.uniform(low=-0.1, high=0.1, size=(n,c))\n",
        "    b = np.array([1, 1, 1])\n",
        "    for epoch in range(epochs):\n",
        "        y_hot = one_hot(y, c)\n",
        "        z_val = np.dot(X,w)+ b\n",
        "        y_pred = softmax(z_val)\n",
        "        w_gradient = (1/m)*np.dot(X.T, (y_pred - y_hot)) \n",
        "        w = w - lr*w_gradient\n",
        "    return w, b"
      ],
      "metadata": {
        "id": "ZbDbUS4x8ZQl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, b = fit(x_train, y_train, lr=0.85, c=3, epochs=60000)"
      ],
      "metadata": {
        "id": "LGNcvkoD8c7d"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the output with the computed weight and bias\n",
        "# getting the class which has maximum probability\n",
        "def predict(X, w, b):\n",
        "    z_val = X@w + b\n",
        "    y_predictions = softmax(z_val)\n",
        "    return np.argmax(y_predictions, axis=1)"
      ],
      "metadata": {
        "id": "ha7QBEzX8oVy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y, y_prds):\n",
        "    return np.sum(y==y_prds)/len(y)"
      ],
      "metadata": {
        "id": "fsECTJ_Q8r53"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_preds = predict(x_train, w, b)\n",
        "print(x_train.shape)\n",
        "print(f'Accuracy: {accuracy(y_train, train_preds)}')\n",
        "test_data = test.iloc[:,0:3]\n",
        "x_test= test_data.values\n",
        "x_test=x_test.astype('float64')\n",
        "test_preds = predict(x_test, w, b)\n",
        "print(train_preds)\n",
        "print(test_preds)\n",
        "print(y_train.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ4dU6Iz8uw1",
        "outputId": "72a900f8-f725-4c5b-feaa-5948437239cb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8083333333333333\n",
            "[0 2 1 1 0 2 0 0 0 1 2 0 0 0 2 1 1 2 0 2 0 2 1 2 1 0 0 0 1 1 1 2 1 0 0 0 0\n",
            " 1 2 0 2 0 0 0 1 2 2 0 0 2 2 1 2 2 0 2 0 1 0 0 2 2 2 2 0 2 0 2 2 1 1 0 2 0\n",
            " 0 2 0 0 2 2 0 1 0 0 1 2 0 0 0 1 0 2 2 0 0 0 2 1 2 1 1 0 0 0 2 2 2 0 2 2 2\n",
            " 2 2 0 0 0 0 0 0 0]\n",
            "[2 2 0 0]\n",
            "[0 2 0 2 0 2 2 1 0 1 2 0 0 0 1 1 2 2 0 2 1 2 2 2 1 0 1 0 1 1 1 2 1 1 0 0 0\n",
            " 1 2 2 1 1 0 0 1 2 2 0 0 2 1 1 2 2 0 2 1 1 1 0 2 2 1 2 0 2 0 2 2 0 1 1 2 0\n",
            " 0 2 0 0 2 2 0 1 0 0 2 2 0 0 0 1 1 2 2 0 0 1 2 2 2 1 1 0 0 0 2 2 2 0 2 2 2\n",
            " 2 2 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing the results of the softmax regression using 4 features and 3 features--> softmax regression using 4 features performs better than 3 features \n",
        "because softmax regression fits complicated hyperplane to separate more than two probability distributions from the exponential family, making it well-suited for high-dimensional datasets with a large number of training points. However, if the data is not linearly separable, the algorithm may not work effectively."
      ],
      "metadata": {
        "id": "19Rjoi2qeEk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  predictions = 0\n",
        "  for i, testsample in data.iterrows():\n",
        "    sample = testsample.values[:3]\n",
        "    endresult = testsample.values[4]\n",
        "    dataa = data.drop(i)\n",
        "    dataax= dataa.iloc[:,0:3]\n",
        "    dataay= dataa.iloc[:,4]\n",
        "    dataax=dataax.astype('float64')\n",
        "    dataax= dataax.values\n",
        "    dataay=dataay.astype('float64')\n",
        "    sample=sample.astype('float64')\n",
        "    dataay= dataay.values\n",
        "    w, b  = fit(dataax, dataay, lr=0.5, c=3, epochs=10000)\n",
        "    z_val = sample@w + b\n",
        "    y_preds = softmax(z_val)\n",
        "    #print(y_preds.shape)\n",
        "    predictvalue= np.argmax(y_preds)\n",
        "    if predictvalue == endresult:\n",
        "      predictions += 1\n",
        "  print(f\"{predictions}/{data.shape[0]} correct predictions using all features\")\n",
        "  print(f'performance is : ', (predictions/data.shape[0]) * 100)\n",
        "  print()"
      ],
      "metadata": {
        "id": "1H7GieIL8y1a"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnjgYhN591Rf",
        "outputId": "bbef0cec-95af-43db-8f2a-a8f3b60b5399"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/120 correct predictions using all features\n",
            "performance is :  37.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The performance of testing data with the 3 features and 4 features doesn't make any difference"
      ],
      "metadata": {
        "id": "4-2WjUY2fsUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After seeing the results of softmax regression and KNN from assignment 1, KNN gives better result compared to softmax because KNN is a non-parametric, lazy learning algorithm that does not make any assumptions about the underlying data distribution while Softmax Regression is a parametric, eager learning algorithm that assumes that the data follows a certain distribution and tries to learn a model that can generalize to new data.\n",
        "\n",
        "KNN is based on the assumption that points that are close to each other in the feature space are likely to have the same label. However, it can suffer from the curse of dimensionality, making it suitable only for low-dimensional datasets with a small number of samples as it can be very slow otherwise. In contrast, softmax regression fits complicated hyperplane to separate more than two probability distributions from the exponential family, making it well-suited for high-dimensional datasets with a large number of training points. However, if the data is not linearly separable, the algorithm may not work effectively.\n",
        "\n",
        "Softmax regression generalizes logistic regression and its Harder to train\n",
        "\n"
      ],
      "metadata": {
        "id": "1g2exUlbemR2"
      }
    }
  ]
}